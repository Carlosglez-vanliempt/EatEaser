{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8318545",
   "metadata": {},
   "source": [
    "<div style='width=100%; display:flex;flex-direction:row'><img  src=https://universidadeuropea.com/resources/media/images/universidad-europea-logo_poc9mEM.original.png width=100  style='  margin-left: auto;margin-right: auto; width: 25%; height:25%;'><img  src=https://i.ibb.co/1068C7j/EATEASER.jpg width=100 style='  margin-left: auto;margin-right: auto; width: 10%;height:25%;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee9dce",
   "metadata": {},
   "source": [
    "<div style='margin:auto;text-align: center;font-family: \"Times New Roman\", Times, serif; font-weight: bold;'>PROYECTO COMUTACIONAL<br><br>EATEASER - VOZ A TEXTO</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329ef59",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex;flex-direction:row'>\n",
    "    <div style='width:50%;margin-right:5cm;'>\n",
    "        <p style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;'>ESTUDIANTES</p>\n",
    "<ul style='font-family: \"Times New Roman\", Times, serif;'>\n",
    "    <li>Adilem Dobras 21911633</li><li>Roberto Echevarria 21823680</li><li>Carlos Gonzales 22067726</li><li>Juan Carlos Rondeau 21816176</li></ul> </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3dfd23",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">1. Importamos las librerias</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e13fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlow\\.conda\\envs\\EatEaser\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Carlow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Carlow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pathlib\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import numpy\n",
    "\n",
    "try:\n",
    "    from pytube import YouTube\n",
    "    from pytube import Playlist\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pytube\n",
    "    from pytube import YouTube\n",
    "    from pytube import Playlist\n",
    "try:\n",
    "    import speech_recognition as sr\n",
    "except ModuleNotFoundError:\n",
    "    !pip install SpeechRecognition\n",
    "    import speech_recognition as sr\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "except:\n",
    "    !pip install pydub\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "try:\n",
    "    import moviepy.editor as mp\n",
    "except:\n",
    "    !pip install moviepy\n",
    "    import moviepy.editor as mp\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except:\n",
    "    !pip install beautifulsoup4\n",
    "    from bs4 import BeautifulSoup\n",
    "try:\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "except:\n",
    "    !pip install nltk\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    import pyrebase\n",
    "except:\n",
    "    !pip install pyrebase4\n",
    "    import pyrebase\n",
    "try:   \n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    !pip install nltk\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bce916",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">2. Inicio del programa</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5340a",
   "metadata": {},
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE CONTROLADORVIDEO</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>En esta clase se realizará los ajustes para manejar el video recibido y manipularlo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb88615",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ControladorVideo:\n",
    "    def __init__(self,enlace): \n",
    "        fb=Firebase('recetastextos/')\n",
    "        self._idvideo = fb.reenumerar()\n",
    "        self.enlacevideo=enlace\n",
    "        self.yt=YouTube(self.enlacevideo)\n",
    "        self.nombrevideo=''\n",
    "        self.titulovideo=self.yt.title\n",
    "        self.autorvideo=self.yt.author\n",
    "        self.fechavideo=self.yt.publish_date\n",
    "        self.duracionvideo=self.yt.length\n",
    "        self.rec=RecursosAdicionales()\n",
    "    \"\"\"|DESCARGAR VIDEO URL: descarga el video de youtube\n",
    "       |return: devuelve una ruta absoluta\"\"\"\n",
    "    def descargarVideoURL(self):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #aqui creo un nuevo id para el nuevo video\n",
    "        self._idvideo= self._idvideo+1\n",
    "        #esta sera el archivo del video y su nuevo nombre\n",
    "        nombre='receta'+str(self._idvideo)\n",
    "        #le pedimos al pytube que solo nos descargue el audio y lo descargamos\n",
    "        t=self.yt.streams.filter(file_extension='mp4').first().download(output_path=recetasVideos,filename=nombre+'.mp4')\n",
    "        #devolvemos el nombre\n",
    "        return nombre\n",
    "    \"\"\"|PARSEO VIDEO: pasa el video de .mp4 a .wav\n",
    "       |nombre: es un string que se colocara el nombre del video\n",
    "       |return: devuelve el nuevo nombre del audio en .wav\"\"\"\n",
    "    def parseoVideo(self,nombre):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #tomamos el video en mp4 \n",
    "        track = mp.VideoFileClip(recetasVideos+nombre+'.mp4')\n",
    "        #cambiamos el video a .wav\n",
    "        nombre_wav=\"{}.wav\".format(nombre)\n",
    "        track.audio.write_audiofile(recetasVideos+nombre_wav)\n",
    "        track.close()\n",
    "        return nombre\n",
    "    \"\"\"|SPEECH TEXT:Transforma el audio a texto\n",
    "       |nombre: es un string que se colocara el nombre del video\n",
    "       |return: devuelve un string con el texto devuelto\"\"\"\n",
    "    def speech_text(self,nombre):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #instanciamos el recognizer\n",
    "        r = sr.Recognizer()\n",
    "        audio = sr.AudioFile(recetasVideos+nombre)\n",
    "        with audio as source:\n",
    "            audio_file = r.record(source)\n",
    "        #transcribimos el audio a texto\n",
    "        result = r.recognize_google(audio_file, language = 'es-ES')\n",
    "        return result\n",
    "    def data_json(self):\n",
    "        return {\"id\":self._idvideo, \"nombre\":self.titulovideo, \"autor\": self.autorvideo, \"fecha\":str(self.fechavideo),\"enlace\":str(self.enlacevideo)}\n",
    "    def indexar_datos(self):\n",
    "        return self.rec.indexar_datos(\"recetastextos/indice.json\",{\"id\":self._idvideo+1, \"nombre\":self.titulovideo, \"autor\": self.autorvideo, \"fecha\":str(self.fechavideo),\"enlace\":str(self.enlacevideo)})\n",
    "    \"\"\"|REPETIDO:Nos dice si el video ya se encuentra en nuestra bd\n",
    "       |fileName: nombre del json\n",
    "       |key: llave en donde queremos encontrar lo que buscamos\n",
    "       |buscar: elemento que estamos buscando\"\"\"\n",
    "    def repetido(self):\n",
    "        return self.rec.buscar_json('recetastextos/indice.json','nombre',self.titulovideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b297ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE DEPURADOR</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>En esta clase se realizará el proceso de extraccion, transformacion y carga de nuestro programa EATEASER.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0598a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#si el video es mayor de 3 minutos no funciona\n",
    "#si el video es en ingles no funciona\n",
    "class Depurador:\n",
    "    def __init__(self): \n",
    "        self.rec=RecursosAdicionales()\n",
    "    \"\"\"|VIDEO: proceso etl donde extraemos al informacion del video \n",
    "       |enlace: es un string que se colocara el enlace del video\"\"\"\n",
    "    def video(self,enlace):\n",
    "        try:\n",
    "            #instanciamos el controlador de videos\n",
    "            cv=ControladorVideo(enlace)\n",
    "            fb=Firebase('recetastextos/')\n",
    "            \n",
    "            #paso 1: verificamos si existe en la database\n",
    "            if fb.validar_database(cv.titulovideo)==False:\n",
    "                #paso 2: guardamos en database datos principales\n",
    "                \n",
    "                #paso 3: descargamos el video\n",
    "                cv.nombrevideo=cv.descargarVideoURL()\n",
    "                print(\"id: \"+str(cv._idvideo))\n",
    "                fb.guardar_database(cv.data_json(),cv._idvideo)\n",
    "                #paso 4: pasamos el video a .wav\n",
    "                nombre=cv.parseoVideo(cv.nombrevideo)\n",
    "                #paso 5: evaluamos los silencios \n",
    "                try:                \n",
    "                    num_segm=self.rec.segcionarXsilencios(nombre)\n",
    "                    result=\"\"\n",
    "                    for i in range(num_segm):\n",
    "                        try:\n",
    "                            result=result+str(cv.speech_text(\"../temp_audios/{}_extracto{}.wav\".format(nombre,i+1)))\n",
    "                            result=result+\" \"\n",
    "                        except BaseException:\n",
    "                            logging.exception(\"An exception was thrown!\")\n",
    "                            audio1=AudioSegment.from_wav(\"temp_audios/{}_extracto{}.wav\".format(nombre,i+1))\n",
    "                            duracion=audio1.duration_seconds\n",
    "                            if duracion<=5:\n",
    "                                print(\"El extracto {} es un silencio\".format(i+1))\n",
    "                            elif duracion<=180:\n",
    "                                print(\"El extracto {} es música o ruido\".format(i+1))\n",
    "                            else:\n",
    "                                print(\"Error importante en el extracto {}\".format(i+1))\n",
    "                    #paso 6: borramos los chunks temporales de audio\n",
    "                    self.rec.eliminacion_audio(\"temp_audios\",\"wav\")\n",
    "                    try:\n",
    "                        quitarEmojis = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 'NULL')\n",
    "                        tituloSinEmojis=cv.titulovideo.translate(quitarEmojis)\n",
    "                        autorSinEmojis=cv.autorvideo.translate(quitarEmojis)\n",
    "                        #paso 7: escribimos el texto recibido en un txt->se guarda en local\n",
    "                        resultado=self.rec.escritura(cv.nombrevideo,\"Titulo:\"+tituloSinEmojis+\"\\n\"+\"Autor:\"+autorSinEmojis+\"\\n\"+\"Fecha Publicacion:\"+str(cv.fechavideo)+\"\\n\"+\"Enlace: \"+str(cv.enlacevideo)+\"\\n\"+\"Entradilla:\"+result)\n",
    "                        #paso 8: guardamos el texto en una base de datos\n",
    "                        fb.guardar_firebase(cv.nombrevideo+'.txt')\n",
    "                        #paso 9: eliminamos los mp4\n",
    "                        self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                    except BaseException:\n",
    "                        logging.exception(\"An exception was thrown!\")\n",
    "                        print(\"No se ha podido eliminar los caracteres corruptos el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo)\n",
    "                        self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                        return None   \n",
    "                except BaseException:\n",
    "                    logging.exception(\"An exception was thrown!\")\n",
    "                    print(\"No se ha podido transcribir el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo+\" - \"+cv.enlacevideo)\n",
    "                    self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                    self.rec.eliminacion_audio(\"temp_audios\",\"wav\")\n",
    "                    return None\n",
    "            else:\n",
    "                print('Este video se encuentra en la base de datos.')\n",
    "                resultado=\"\"\n",
    "            return resultado\n",
    "        except BaseException:\n",
    "            logging.exception(\"An exception was thrown!\")\n",
    "            print(\"No se ha podido descargar el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo)\n",
    "            return None\n",
    "    def lista(self, enlace):\n",
    "        playlist_urls = Playlist(enlace)\n",
    "        for url in playlist_urls:\n",
    "            self.video(url)\n",
    "    def transformacion(self):\n",
    "        print()\n",
    "    def carga(self):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4d7c8-d246-4fd2-b6ef-6e39143efbe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE RECURSOS ADICIONALES</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c910592f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#aqui iran lecturas-escrituras-guardar-eliminar cosas en bases de datos\n",
    "class RecursosAdicionales:\n",
    "    \"\"\"|ESCRITURA: escribe textos txt\n",
    "       |nombre: nombre del \n",
    "       |return: devuelve el audio en texto\"\"\"    \n",
    "    def escritura(self,nombre,texto):\n",
    "        recetasTextos = './recetastextos/'\n",
    "        if not(os.path.exists(recetasTextos)):\n",
    "            os.mkdir(recetasTextos)\n",
    "        f = open(recetasTextos+nombre+'.txt', 'w')\n",
    "        f.write(texto)\n",
    "        f = open(recetasTextos+nombre+'.txt', \"r\")\n",
    "        print(f.read())\n",
    "        f.close()\n",
    "        \n",
    "    def lectura_json(self,fileName):\n",
    "        if self.documento_vacio(fileName):\n",
    "            with open(fileName, \"r\") as file:\n",
    "                    archivo=json.load(file)\n",
    "        else: \n",
    "            archivo=[]\n",
    "            print('El documento se encuentra vacio.')\n",
    "        return archivo\n",
    "    \n",
    "    def escritura_json(self,fileName,data):\n",
    "        with open(fileName, \"w\") as file:\n",
    "                json.dump(data, file)\n",
    "                file.close()\n",
    "    def buscar_json(self,fileName,key,buscar):\n",
    "        encontrado=False\n",
    "        if self.documento_vacio(fileName):\n",
    "            archivo_json=self.lectura_json(fileName)\n",
    "            for item in archivo_json:\n",
    "                if buscar in item[key]:\n",
    "                    print('encontrado')\n",
    "                    encontrado=True\n",
    "                    #no me gusta usar esto pero no tengo idea de como usar un while con json\n",
    "                    break\n",
    "        return encontrado\n",
    "    def documento_vacio(self,fileName):\n",
    "        return os.stat(fileName).st_size != 0\n",
    "    def indexar_datos(self,fileName,adicion):\n",
    "        if not(os.path.exists(fileName)):\n",
    "            os.mkdir(fileName)\n",
    "        data=[]\n",
    "        data=self.lectura_json(fileName)\n",
    "        data.append(adicion)\n",
    "        self.escritura_json(fileName,data)\n",
    "        \n",
    "    def eliminacion_audio(self,path,tipo):\n",
    "        url = './'+path+'/'\n",
    "        py_files = glob.glob(url+'*.'+tipo)\n",
    "        for py_file in py_files:\n",
    "            try:\n",
    "                os.remove(py_file)\n",
    "            except OSError as e:\n",
    "                print(f\"Error:{ e.strerror}\")\n",
    "    \n",
    "    def segcionarXsilencios(self,audio):\n",
    "        audio1=AudioSegment.from_wav(\"./recetasvideos/\"+audio+\".wav\")\n",
    "        var_min=1900\n",
    "        salir=False\n",
    "        while salir==False:\n",
    "            samples = audio1.get_array_of_samples()\n",
    "            segundo=88521\n",
    "            index=[]\n",
    "            for i in range(0,len(samples),int(segundo/5)):\n",
    "                dataSeg = samples[i:int(segundo/5)+i]\n",
    "                media=numpy.mean(dataSeg)\n",
    "                var=numpy.var(dataSeg)\n",
    "                if -10<=media<=10 and var<=var_min:\n",
    "                    index.append(i)\n",
    "\n",
    "            borrar=[]\n",
    "            guardado=0\n",
    "            for i in range(len(index)-1):\n",
    "                if index[i+1]<=index[i]+(20*segundo):\n",
    "                    if i==0:\n",
    "                        tiempo=(index[i])/segundo\n",
    "                    else:\n",
    "                        tiempo=(index[i+1]-guardado)/segundo\n",
    "                    if tiempo<=120:\n",
    "                        borrar.append(i)\n",
    "                    else:\n",
    "                        guardado=index[i]\n",
    "                else:\n",
    "                    guardado=index[i]\n",
    "\n",
    "            final=numpy.delete(index, borrar, axis=0) \n",
    "            extractos=[]\n",
    "            if len(final)==0:\n",
    "                var_min=var_min*10\n",
    "                salir=False\n",
    "            else:\n",
    "                for i in range(len(final)):\n",
    "                    if i==0:\n",
    "                        extractos.append(samples[:final[i]])\n",
    "                    else:\n",
    "                        extractos.append(samples[final[i-1]:final[i]])\n",
    "                extractos.append(samples[final[i]:])\n",
    "                salir=True\n",
    "\n",
    "        for i in range(len(extractos)):\n",
    "            nombre=\"\"\n",
    "            new_sound = audio1._spawn(extractos[i])\n",
    "            nombre=\"temp_audios/{}_extracto{}.wav\".format(audio,i+1)\n",
    "            new_sound.export(nombre,format=\"wav\")\n",
    "        #print(len(extractos))\n",
    "        return len(extractos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654335c-b3d4-4cde-a6be-8b29d7938953",
   "metadata": {},
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE FIREBASE</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131f35f6-ac5b-4c99-88a3-e47d738b6a5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Firebase:\n",
    "    def __init__(self,ubicacion):\n",
    "        self.ubi=ubicacion\n",
    "        \n",
    "        self.config={\"apiKey\": \"AIzaSyDDg9WOlFJxnEJoxomYtsnkJfsI4TgoL_E\",\"authDomain\": \"eateaser-741d4.firebaseapp.com\",\"databaseURL\" : \"https://eateaser-741d4-default-rtdb.firebaseio.com/\",\"projectId\": \"eateaser-741d4\",\"storageBucket\": \"eateaser-741d4.appspot.com\",\"messagingSenderId\": \"706351391410\",\"appId\": \"1:706351391410:web:6abc2cabd6bf83843b5fab\",\"measurementId\": \"G-YZZCBRHNBT\"};\n",
    "        self.firebase=self.conexion_firebase()\n",
    "        self.database=self.firebase.database()\n",
    "    def conexion_firebase(self):\n",
    "        return pyrebase.initialize_app(self.config)\n",
    "    def guardar_firebase(self,nom):\n",
    "        storage=self.firebase.storage()\n",
    "        storage.child(self.ubi+nom).put(self.ubi+nom)\n",
    "    def eliminar_firebase(self,nom):\n",
    "        self.firebase.storage().delete(self.ubi+nom)\n",
    "    def guardar_database(self,data,_id):\n",
    "        self.database.child('Recetas').child(_id).set(data)\n",
    "    def validar_database(self,data):\n",
    "        validar=self.database.get()\n",
    "        encontrado=False\n",
    "        for a in validar.each():\n",
    "            if  data in str(a.val()):\n",
    "                encontrado=True\n",
    "                #no me gusta usar esto pero no tengo idea de como usar un while con json\n",
    "                break\n",
    "        return encontrado\n",
    "    def reenumerar(self):\n",
    "        recetas=self.database.child(\"Recetas\").get()\n",
    "        id=0\n",
    "        for item in recetas.each():\n",
    "            id=item.key()\n",
    "        return int(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70d448-b2d6-4c9c-b38c-9bc020013d7d",
   "metadata": {},
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE WEB SCRAP</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e747077e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WebScrap:\n",
    "    def __init__(self): \n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    def request(self, url):\n",
    "        request1 = requests.get(url, headers=self.headers)\n",
    "        html = request1.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "    def verificar_alimento(self,alimento):\n",
    "        soup = self.request( 'https://www.themealdb.com/api/json/v1/1/search.php?s='+alimento)\n",
    "        print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517c7a4",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">3. Main</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c5289",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y si tambien vemos si le permitimos al usuario que meta videos?\n",
    "dep=Depurador()\n",
    "if __name__ == '__main__':\n",
    "    #dep.video('https://www.youtube.com/watch?v=6PzQY1E2s2g&list=PLxHmjpcgU5ArC2rY5cpoIcZoVKB_0UHfR&ab_channel=PlatosF%C3%A1cilesconTamara')\n",
    "    #dep.video('https://www.youtube.com/watch?v=PsqR5M8rdjA&list=LL&index=9&t=4s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=xfYcM_jHgPY')\n",
    "    #dep.video('https://www.youtube.com/watch?v=wiCfqc5W-yo')\n",
    "    #error_nuevo#dep.video('https://www.youtube.com/watch?v=3DnPkf9rP_0')\n",
    "    #error_nuevo#dep.video('https://www.youtube.com/watch?v=xVsgKMZFCZY')\n",
    "    #dep.video('https://www.youtube.com/watch?v=rpCe0RPMY94')\n",
    "    #dep.video('https://www.youtube.com/watch?v=rv4gLMa-FYk')\n",
    "    #dep.video('https://www.youtube.com/watch?v=VS8zYxBj4r8')\n",
    "    #dep.video('https://www.youtube.com/watch?v=o99JXrEkZoo')\n",
    "    #dep.video('https://www.youtube.com/watch?v=lKkg5L23b3M')\n",
    "    #dep.video('https://www.youtube.com/watch?v=PsqR5M8rdjA&t=14s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=IvZaAL6qYe0&t=29s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=SIMQBuuyE9M')\n",
    "    #dep.video('https://www.youtube.com/watch?v=_YoZfg7R8Hk')\n",
    "    #dep.video('https://www.youtube.com/watch?v=Zv7KdlOBk7Y')\n",
    "    #dep.video('https://www.youtube.com/watch?v=mFcN4btaZyI&t=2s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=sRmmQBBln9Q')\n",
    "    #dep.video('https://www.youtube.com/watch?v=-QoTJJJfeEE')\n",
    "    #dep.video('https://www.youtube.com/watch?v=JRY5obPKPzo&list=PLxHmjpcgU5ArC2rY5cpoIcZoVKB_0UHfR&index=5&ab_channel=PlatosF%C3%A1cilesconTamara')\n",
    "    #dep.video('https://www.youtube.com/watch?v=stFmx7OCy1k&ab_channel=RecetasdeEsbieta')\n",
    "    #error_videomuylargo#dep.video(\"https://www.youtube.com/watch?v=qqTqePGIjhc\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLQwfLPYiFlOsS9x6zgeZmFRLqDx3poZvw\")\n",
    "    #dep.lista(\"https://www.youtube.com/playlist?list=PLIsSIvqffHZvM2v1QS5Zi0MUL258EKLPq\")\n",
    "    #dep.video('https://www.youtube.com/watch?v=rv4gLMa-FYk')\n",
    "    \n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLf2b-1EmxBEcmcj5GPFfFMbvegVKFOIYR\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL2rWPa7BVMtzadghDZ7cHbkXuJ735RVnZ\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLiIutYe2uQJrwuRzF0_8tf_a651emeOiO\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLEOkiu1MfX7FsiTlZfaHZtMfo1EZD96tq\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL8Vs-hI7gkl0yY6T0qbWSsw_Zv9d2cqnu\")#arroces\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL8Id0yl_4Lo-AtOvrizH3OA6yOK0HLRPw\")#mariscos\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLxHmjpcgU5Apmx0uz4mfhWZmMFrIm-1a8\")#pasta **\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLxHmjpcgU5AqiG1XoX00meJj9rnNIp9qT\")#carnes\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLgDn1_a8qclShfo0yvUUPrX673yC3v8LR\")#pescados y algun marisco\n",
    "    #No acabada # dep.lista(\"https://youtube.com/playlist?list=PLge9wrsFXyuYHweFYpDMnHp95WYe6Prfn\")#verduras\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL1DDoU1JPaGI0ZVkGbXPhUq2ttCVPBKc5\")#arroces\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL75JfQSBdGa9ez55vz1evAkKtI_e8SzCh\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL75JfQSBdGa9RP3HprHJHyLMmM2hC9uu7\")#marisco\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLNvWgJIx6X41jbPxHH0h6I_JJimIKzlVF\")#pasta\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLcPdHx9MSg_DAHTy258b0F1vdZE7nRHYX\")#pescado\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLWwMSMcUrXKFkBuQfR0uNB7E8TL7dnmfY\")#platosMenores\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLdLEn2GksKhaCS9QmsKaHcC4Yr6jCKHf_\")#verduras\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLoNzD53SxXZC84LG74DVYvqYCSwMaVIKn\")#platosMenores\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLUxqTjTdTvkN2JpDMcTKcMxEGZqmJ14Xu\")#platosMenores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfa42e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0./recetastextos/Carpeta Arroz/-----------------\n",
      "1./recetastextos/Carpeta Bebidas/-----------------\n",
      "2./recetastextos/Carpeta Carnes/-----------------\n",
      "3./recetastextos/Carpeta Marisco/-----------------\n",
      "4./recetastextos/Carpeta Pasta/-----------------\n",
      "5./recetastextos/Carpeta Pescados/-----------------\n",
      "6./recetastextos/Carpeta Platos Menores/-----------------\n",
      "7./recetastextos/Carpeta Verduras/-----------------\n",
      "----------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 82>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     81\u001b[0m stemsTesting\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mtratamientoTextos(listaTextosTesting)\n\u001b[1;32m---> 82\u001b[0m stems\u001b[38;5;241m=\u001b[39m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtratamientoTextos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlistaTextosCarpeta\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mProcesarDocumentos.tratamientoTextos\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtratamientoTextos\u001b[39m(\u001b[38;5;28mself\u001b[39m, info):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m#Eliminamos todos los simbolos del texto (,.;:?¿!!) etc\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     textoSinSimbolos \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[^0-9A-Za-z_]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m#Sacamos todos los tokens del texto y los metemos en una lista\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     textoTokenizado \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mword_tokenize(textoSinSimbolos)\n",
      "File \u001b[1;32m~\\.conda\\envs\\EatEaser\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "class ProcesarDocumentos:     \n",
    "    def lectura(self):\n",
    "        procDoc=ProcesarDocumentos()\n",
    "        rutaCarpetasPorCategoria = \"./recetastextos/\"\n",
    "        listaCarpetasFinal = []\n",
    "        #estos string nos servirán para guardar todos los textos de los txt por cada una de las carpetas\n",
    "        carpetaArroz = carpetaBebidas = carpetaCarnes = carpetaMarisco = carpetaPasta = carpetaPescados = carpetaPlatosMenores = carpetaVerduras = ''\n",
    "        #sacamos una lista de todas las carpetas\n",
    "        listaCarpetas = os.listdir(rutaCarpetasPorCategoria)\n",
    "        #recorremos todas las carpetas\n",
    "        i=0\n",
    "        for lc in listaCarpetas:\n",
    "            #cogemos el nombre de la carpeta y se lo concatenamos a la ruta anterior\n",
    "            rutaPorCarpeta = rutaCarpetasPorCategoria + lc + '/'\n",
    "            print(str(i)+rutaPorCarpeta+'-----------------')\n",
    "            if(i==0):\n",
    "                carpetaArroz = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                #print(carpetaArroz)\n",
    "                listaCarpetasFinal.append(carpetaArroz)\n",
    "            if(i==1):\n",
    "                carpetaBebidas = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaBebidas)\n",
    "            if(i==2):\n",
    "                carpetaCarnes = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaCarnes)\n",
    "            if(i==3):\n",
    "                carpetaMarisco = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaMarisco)\n",
    "            if(i==4):\n",
    "                carpetaPasta = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPasta)\n",
    "            if(i==5):\n",
    "                carpetaPescados = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPescados)\n",
    "            if(i==6):\n",
    "                carpetaPlatosMenores = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPlatosMenores)\n",
    "            if(i==7):\n",
    "                carpetaVerduras = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaVerduras)\n",
    "            i=i+1\n",
    "        return listaCarpetasFinal\n",
    "    def lecturaTesting(self):\n",
    "        procDoc=ProcesarDocumentos()\n",
    "        rutaCarpetaTesting = \"./recetastextostesting/Carpeta Testing/\"\n",
    "        carpetaTesting = procDoc.resultadoStringCarpeta(rutaCarpetaTesting)\n",
    "        return carpetaTesting\n",
    "    def resultadoStringCarpeta(self, rutaPorCarpeta):\n",
    "        strCarpeta=''\n",
    "        #vemos el contenido de la carpeta en la que estamos iterando\n",
    "        listaTxt = os.listdir(rutaPorCarpeta)\n",
    "        #recorremos todos los archivos de la carpeta\n",
    "        for lt in listaTxt:\n",
    "            #concatenamos la ruta de la carpeta con el nombre de los archivos que contiene esta\n",
    "            rutaTxt = rutaPorCarpeta + lt\n",
    "            #al ir iterando pasaremos por todos los archivos modificando la variable de la ruta para poder hacer un open con ella\n",
    "            with open(rutaTxt, 'r') as f: \n",
    "                #al hacer el open leemos lo que hay dentro del archivo con f.read(), y esto lo guardamos dentro de un string inicializado al inicio del todo\n",
    "                strCarpeta = strCarpeta + f.read()\n",
    "        return strCarpeta\n",
    "    def leer_stopwords(self, path):\n",
    "        with open(path) as f:\n",
    "            # Lee las stopwords del archivo y las guarda en una lista\n",
    "            mis_stopwords = [line.strip() for line in f]\n",
    "        return mis_stopwords\n",
    "    def tratamientoTextos(self, info):\n",
    "        #Eliminamos posibles horas del titulo\n",
    "        textoSinSimbolos = re.sub(\"\\d+:\\d+:\\d+\", \"\" , info)\n",
    "        #Eliminamos posibles fechas\n",
    "        textoSinSimbolos = re.sub(\"\\d+-\\d+-\\d+\", \"\" , textoSinSimbolos)\n",
    "        #Eliminamos todos los fin de enlace\n",
    "        textoSinSimbolos = re.sub(\"v=.*\", \"\" , textoSinSimbolos)\n",
    "        #Eliminamos todos los simbolos del texto (,.;:?¿!!) etc\n",
    "        textoSinSimbolos = re.sub(\"[^0-9A-Za-z_]\", \" \" , textoSinSimbolos)\n",
    "        #Sacamos todos los tokens del texto y los metemos en una lista\n",
    "        textoTokenizado = nltk.tokenize.word_tokenize(textoSinSimbolos)\n",
    "        #una lista no tiene lower asique pasamos el lower con map a toda la lista\n",
    "        textoMinusculas = (map(lambda x: x.lower(), textoTokenizado))\n",
    "        #Le pasa un stopword de palabras en español a la lista de palabras que le llega\n",
    "        #stop_words_sp = set(stopwords.words('spanish'))\n",
    "        stop_words_sp = self.leer_stopwords(\"./rapidminer/stop_words_spanish.txt\")\n",
    "        pasarStopWords = [i for i in textoMinusculas if i not in stop_words_sp]\n",
    "        #Aplicamos la normalizacion mediante stemming\n",
    "        #SnowStem = nltk.SnowballStemmer(language = 'spanish')\n",
    "        # Crear un objeto SnowballStemmer para el idioma español\n",
    "        stemmer = RSLPStemmer()\n",
    "        listaStems = [stemmer.stem(word) for word in pasarStopWords]\n",
    "        return nltk.FreqDist(listaStems)\n",
    "\n",
    "\n",
    "p=ProcesarDocumentos()\n",
    "listaTextosCarpeta=p.lectura()\n",
    "listaTextosTesting=p.lecturaTesting()\n",
    "print('----------------------------')\n",
    "stemsTesting=p.tratamientoTextos(listaTextosTesting)\n",
    "stems=p.tratamientoTextos(listaTextosCarpeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6d2add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     C:\\Users\\Carlow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "0.996875\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Marisco\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         Carpeta Arroz       0.93      0.82      0.87        17\n",
      "       Carpeta Bebidas       0.87      1.00      0.93        20\n",
      "        Carpeta Carnes       0.69      0.58      0.63        19\n",
      "       Carpeta Marisco       0.75      0.26      0.39        23\n",
      "         Carpeta Pasta       0.80      0.94      0.86        17\n",
      "      Carpeta Pescados       0.61      0.83      0.70        23\n",
      "Carpeta Platos Menores       0.80      0.67      0.73        12\n",
      "      Carpeta Verduras       0.47      1.00      0.64         7\n",
      "\n",
      "              accuracy                           0.73       138\n",
      "             macro avg       0.74      0.76      0.72       138\n",
      "          weighted avg       0.75      0.73      0.71       138\n",
      "\n",
      "[[14  0  0  0  0  2  0  1]\n",
      " [ 0 20  0  0  0  0  0  0]\n",
      " [ 0  0 11  1  2  1  1  3]\n",
      " [ 1  3  1  6  1  8  1  2]\n",
      " [ 0  0  0  0 16  0  0  1]\n",
      " [ 0  0  2  0  1 19  0  1]\n",
      " [ 0  0  2  1  0  1  8  0]\n",
      " [ 0  0  0  0  0  0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('snowball_data')\n",
    "\n",
    "def stemming(text):\n",
    "    stemmer = nltk.stem.SnowballStemmer('spanish')\n",
    "    return [stemmer.stem(word) for word in nltk.word_tokenize(text)]\n",
    "\n",
    "# Leer los documentos\n",
    "documents = []\n",
    "categories = []\n",
    "\n",
    "# Iterar sobre cada carpeta\n",
    "for category in os.listdir('./recetastextos/'):\n",
    "  # Iterar sobre cada documento en la carpeta\n",
    "  for document in os.listdir('./recetastextos/' + category):\n",
    "    # Leer el texto del documento\n",
    "    with open('./recetastextos/' + category + '/' + document, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Añadir el texto y la categoría a las listas\n",
    "    documents.append(text)\n",
    "    categories.append(category)\n",
    "\n",
    "# Crear una lista de tuplas con el texto y la categoría de cada documento\n",
    "print(len(documents))\n",
    "X = list(zip(documents, categories))\n",
    "\n",
    "# Preprocesar los documentos de texto\n",
    "vectorizer = CountVectorizer(analyzer=stemming)\n",
    "X_vectors = vectorizer.fit_transform([x[0] for x in X])\n",
    "\n",
    "# Crear un conjunto de entrenamiento y otro de pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, [x[1] for x in X], test_size=0.3)\n",
    "\n",
    "# Crear y entrenar el modelo de random forest con el conjunto de entrenamiento\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar la precisión del modelo en el conjunto de entrenamiento\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "# Hacer predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Mostrar las predicciones y las etiquetas reales del conjunto de pruebas\n",
    "for yp, yt in zip(y_pred, y_test):\n",
    "    print('Predicción:', yp, '| Etiqueta real:', yt)\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e138d919-f590-4257-9f23-5db0edd53a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     C:\\Users\\Carlow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "0.703125\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Marisco\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pescados\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Verduras | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Platos Menores\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Pescados | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Bebidas | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Platos Menores | Etiqueta real: Carpeta Carnes\n",
      "Predicción: Carpeta Marisco | Etiqueta real: Carpeta Verduras\n",
      "Predicción: Carpeta Arroz | Etiqueta real: Carpeta Bebidas\n",
      "Predicción: Carpeta Carnes | Etiqueta real: Carpeta Arroz\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "Predicción: Carpeta Pasta | Etiqueta real: Carpeta Pasta\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         Carpeta Arroz       0.46      0.71      0.56        17\n",
      "       Carpeta Bebidas       0.95      0.80      0.87        25\n",
      "        Carpeta Carnes       0.32      0.50      0.39        14\n",
      "       Carpeta Marisco       0.29      0.25      0.27        16\n",
      "         Carpeta Pasta       0.57      0.65      0.60        20\n",
      "      Carpeta Pescados       0.44      0.41      0.42        17\n",
      "Carpeta Platos Menores       0.62      0.33      0.43        15\n",
      "      Carpeta Verduras       0.38      0.21      0.27        14\n",
      "\n",
      "              accuracy                           0.51       138\n",
      "             macro avg       0.50      0.48      0.48       138\n",
      "          weighted avg       0.54      0.51      0.51       138\n",
      "\n",
      "[[12  0  2  2  0  1  0  0]\n",
      " [ 3 20  1  0  0  1  0  0]\n",
      " [ 0  0  7  1  4  0  2  0]\n",
      " [ 3  0  4  4  1  2  0  2]\n",
      " [ 4  0  1  0 13  2  0  0]\n",
      " [ 3  0  1  2  2  7  0  2]\n",
      " [ 0  0  4  1  3  1  5  1]\n",
      " [ 1  1  2  4  0  2  1  3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('snowball_data')\n",
    "\n",
    "def stemming(text):\n",
    "    stemmer = nltk.stem.SnowballStemmer('spanish')\n",
    "    return [stemmer.stem(word) for word in nltk.word_tokenize(text)]\n",
    "\n",
    "# Leer los documentos\n",
    "documents = []\n",
    "categories = []\n",
    "\n",
    "# Iterar sobre cada carpeta\n",
    "for category in os.listdir('./recetastextos/'):\n",
    "  # Iterar sobre cada documento en la carpeta\n",
    "  for document in os.listdir('./recetastextos/' + category):\n",
    "    # Leer el texto del documento\n",
    "    with open('./recetastextos/' + category + '/' + document, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Añadir el texto y la categoría a las listas\n",
    "    documents.append(text)\n",
    "    categories.append(category)\n",
    "\n",
    "# Crear una lista de tuplas con el texto y la categoría de cada documento\n",
    "print(len(documents))\n",
    "X = list(zip(documents, categories))\n",
    "\n",
    "# Preprocesar los documentos de texto\n",
    "vectorizer = CountVectorizer(analyzer=stemming)\n",
    "X_vectors = vectorizer.fit_transform([x[0] for x in X])\n",
    "\n",
    "# Crear un conjunto de entrenamiento y otro de pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, [x[1] for x in X], test_size=0.3)\n",
    "\n",
    "# Crear y entrenar el modelo de random forest con el conjunto de entrenamiento\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar la precisión del modelo en el conjunto de entrenamiento\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "# Hacer predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Mostrar las predicciones y las etiquetas reales del conjunto de pruebas\n",
    "for yp, yt in zip(y_pred, y_test):\n",
    "    print('Predicción:', yp, '| Etiqueta real:', yt)\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a53ae9-6724-40ee-9d69-cda732b3cdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
